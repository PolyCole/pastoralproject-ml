{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Maybe need to alter this to function with S3.\n",
    "path_to_file = \"poems_final.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 5085301 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='latin-1')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Duhg9NrUymwO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Pontalba Apartments in the View-Master\n",
      "and the cardboard cathedral as if trapped in the dream\n",
      "twenty years early, the whole a furious search\n",
      "as if for a reason. Still, it's sex that spoils it, isn't it?\n",
      "\n",
      "Jackson Square was the smallest sufficien\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlCgQBRVymwR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IalZLbvOzf-F"
   },
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FYyNlCNXymwY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '\"' :   3,\n",
      "  '#' :   4,\n",
      "  '$' :   5,\n",
      "  '%' :   6,\n",
      "  '&' :   7,\n",
      "  \"'\" :   8,\n",
      "  '(' :   9,\n",
      "  ')' :  10,\n",
      "  '*' :  11,\n",
      "  '+' :  12,\n",
      "  ',' :  13,\n",
      "  '-' :  14,\n",
      "  '.' :  15,\n",
      "  '/' :  16,\n",
      "  '0' :  17,\n",
      "  '1' :  18,\n",
      "  '2' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1VKcQHcymwb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\nThe Pontalba' ---- characters mapped to int ---- > [ 0 51 69 66  1 47 76 75 81 62 73 63 62]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 13 characters from the text are mapped to integers\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0UHJDA39zf-O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "T\n",
      "h\n",
      "e\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l4hkDU3i7ozi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\nThe Pontalba Apartments in the View-Master\\nand the cardboard cathedral as if trapped in the dream\\ntw'\n",
      "\"enty years early, the whole a furious search\\nas if for a reason. Still, it's sex that spoils it, isn'\"\n",
      "'t it?\\n\\nJackson Square was the smallest sufficient landscape,\\nbut that was before, and now the gates a'\n",
      "'re locked\\nat sundown, and the smell of the river fails,\\nfalls ever backward. Some of us lived there, '\n",
      "'though:\\nWhat shall we say who have knowledge\\ncarried to the heart? Back then those flat facades\\nshone'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "  input_text = chunk[:-1]\n",
    "  target_text = chunk[1:]\n",
    "  return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNbw-iR0ymwj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  '\\nThe Pontalba Apartments in the View-Master\\nand the cardboard cathedral as if trapped in the dream\\nt'\n",
      "Target data: 'The Pontalba Apartments in the View-Master\\nand the cardboard cathedral as if trapped in the dream\\ntw'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0eBu9WZG84i0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 0 ('\\n')\n",
      "  expected output: 51 ('T')\n",
      "Step    1\n",
      "  input: 51 ('T')\n",
      "  expected output: 69 ('h')\n",
      "Step    2\n",
      "  input: 69 ('h')\n",
      "  expected output: 66 ('e')\n",
      "Step    3\n",
      "  input: 66 ('e')\n",
      "  expected output: 1 (' ')\n",
      "Step    4\n",
      "  input: 1 (' ')\n",
      "  expected output: 47 ('P')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "  print(\"Step {:4d}\".format(i))\n",
    "  print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "  print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2pGotuNzf-S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwsrpOik5zhv"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size = len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-_70kKAPrPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 134) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vPGmAAXmVLGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           34304     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 134)           137350    \n",
      "=================================================================\n",
      "Total params: 4,109,958\n",
      "Trainable params: 4,109,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqFMUQc_UFgM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 65,  26,  35, 105,   6,  67,  51,  82,  23,  72,  86,  89,  21,\n",
       "       118,  54,  85,  17,  84, 126,  54, 107, 131,  94, 133,  25, 110,\n",
       "        58, 115,  17,  12,  49,  49,  43,  25,  47,  31,  27,  53,  68,\n",
       "        39,  92,  73, 133,  57,  42, 133,  85,  30,  19,  57,  47,  28,\n",
       "        86,  88,  55, 103, 126, 132, 126,  55,  20,  43,  25,  97,  15,\n",
       "        18,  95,  43, 119,   0,  69,  62,  37, 101,  35,  85, 106,  38,\n",
       "        64,  36,  46,  34,  35, 124,  43,  43, 119,  89,   1,  44, 130,\n",
       "        79,  35, 119,  32, 101, 122, 100,  31,  56])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWcFwPwLSo05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " '\"\\n\"\\n\\napril is a dog\\'s dream\\n\\nthe soft grass is growing\\n\\nthe sweet breeze is blowing\\n\\nthe air all ful'\n",
      "\n",
      "Next Char Predictions: \n",
      " 'd9D¦%fTu6ky|4¶Wx0wÅW¨é\\x83ó8«[±0+RRL8P?:VgH\\x81lóZKóx=2ZP;y{X¤ÅïÅX3L8\\x8b.1\\x86L¹\\nhaF¡Dx§GcEOCD¿LL¹| MèrD¹A¡¼\\xa0?Y'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4HrXTACTdzY-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 134)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.89684\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6XBUUavgF56"
   },
   "source": [
    "Use a `tf.keras.callbacks.ModelCheckpoint` to ensure that checkpoints are saved during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6fWTriUZP-n"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yGBE2zxMMHs"
   },
   "outputs": [],
   "source": [
    "EPOCHS=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UK-hmKjYVoll",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "786/786 [==============================] - 1089s 1s/step - loss: 2.0479\n",
      "Epoch 2/30\n",
      "786/786 [==============================] - 961s 1s/step - loss: 1.5888\n",
      "Epoch 3/30\n",
      "786/786 [==============================] - 918s 1s/step - loss: 1.4985\n",
      "Epoch 4/30\n",
      "786/786 [==============================] - 947s 1s/step - loss: 1.4518\n",
      "Epoch 5/30\n",
      "786/786 [==============================] - 922s 1s/step - loss: 1.4203\n",
      "Epoch 6/30\n",
      "786/786 [==============================] - 942s 1s/step - loss: 1.3953\n",
      "Epoch 7/30\n",
      "786/786 [==============================] - 972s 1s/step - loss: 1.3744\n",
      "Epoch 8/30\n",
      "786/786 [==============================] - 913s 1s/step - loss: 1.3559\n",
      "Epoch 9/30\n",
      "786/786 [==============================] - 951s 1s/step - loss: 1.3397\n",
      "Epoch 10/30\n",
      "786/786 [==============================] - 905s 1s/step - loss: 1.3253\n",
      "Epoch 11/30\n",
      "786/786 [==============================] - 896s 1s/step - loss: 1.3123\n",
      "Epoch 12/30\n",
      "786/786 [==============================] - 931s 1s/step - loss: 1.3017\n",
      "Epoch 13/30\n",
      "786/786 [==============================] - 907s 1s/step - loss: 1.2925\n",
      "Epoch 14/30\n",
      "786/786 [==============================] - 914s 1s/step - loss: 1.2842\n",
      "Epoch 15/30\n",
      "786/786 [==============================] - 902s 1s/step - loss: 1.2783\n",
      "Epoch 16/30\n",
      "786/786 [==============================] - 919s 1s/step - loss: 1.2735\n",
      "Epoch 17/30\n",
      "786/786 [==============================] - 900s 1s/step - loss: 1.2700\n",
      "Epoch 18/30\n",
      "786/786 [==============================] - 901s 1s/step - loss: 1.2673\n",
      "Epoch 19/30\n",
      "786/786 [==============================] - 910s 1s/step - loss: 1.2657\n",
      "Epoch 20/30\n",
      "786/786 [==============================] - 905s 1s/step - loss: 1.2642\n",
      "Epoch 21/30\n",
      "786/786 [==============================] - 931s 1s/step - loss: 1.2651\n",
      "Epoch 22/30\n",
      "786/786 [==============================] - 943s 1s/step - loss: 1.2660\n",
      "Epoch 23/30\n",
      "786/786 [==============================] - 968s 1s/step - loss: 1.2678\n",
      "Epoch 24/30\n",
      "786/786 [==============================] - 944s 1s/step - loss: 1.2713\n",
      "Epoch 25/30\n",
      "786/786 [==============================] - 954s 1s/step - loss: 1.2729\n",
      "Epoch 26/30\n",
      "786/786 [==============================] - 934s 1s/step - loss: 1.2770\n",
      "Epoch 27/30\n",
      "786/786 [==============================] - 943s 1s/step - loss: 1.2803\n",
      "Epoch 28/30\n",
      "786/786 [==============================] - 934s 1s/step - loss: 1.2852\n",
      "Epoch 29/30\n",
      "786/786 [==============================] - 943s 1s/step - loss: 1.2901\n",
      "Epoch 30/30\n",
      "786/786 [==============================] - 934s 1s/step - loss: 1.2968\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zk2WJ2-XjkGz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/ckpt_30'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LycQ-ot_jjyu"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71xa6jnYVrAN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            34304     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 134)            137350    \n",
      "=================================================================\n",
      "Total params: 4,109,958\n",
      "Trainable params: 4,109,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, temperature, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 1000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "    predictions = model(input_eval)\n",
    "    # remove the batch dimension\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "    # using a categorical distribution to predict the character returned by the model\n",
    "    predictions = predictions / temperature\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "    # We pass the predicted character as the next input to the model\n",
    "    # along with the previous hidden state\n",
    "    input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = open(\"pastoral_word_seeds.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktovv0RFhrkn",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples/1.txt 0.86\n",
      "samples/2.txt 0.68\n",
      "samples/3.txt 0.21\n",
      "samples/4.txt 0.98\n",
      "samples/5.txt 0.77\n",
      "samples/6.txt 0.66\n",
      "samples/7.txt 0.71\n",
      "samples/8.txt 0.53\n",
      "samples/9.txt 0.34\n",
      "samples/10.txt 0.13\n",
      "samples/11.txt 0.47\n",
      "samples/12.txt 0.2\n",
      "samples/13.txt 0.05\n",
      "samples/14.txt 0.86\n",
      "samples/15.txt 0.65\n",
      "samples/16.txt 0.72\n",
      "samples/17.txt 0.76\n",
      "samples/18.txt 0.76\n",
      "samples/19.txt 0.1\n",
      "samples/20.txt 0.48\n",
      "samples/21.txt 0.17\n",
      "samples/22.txt 0.85\n",
      "samples/23.txt 0.44\n",
      "samples/24.txt 0.39\n",
      "samples/25.txt 0.19\n",
      "samples/26.txt 0.78\n",
      "samples/27.txt 0.45\n",
      "samples/28.txt 0.97\n",
      "samples/29.txt 0.36\n",
      "samples/30.txt 0.38\n",
      "samples/31.txt 0.47\n",
      "samples/32.txt 0.87\n",
      "samples/33.txt 0.96\n",
      "samples/34.txt 0.87\n",
      "samples/35.txt 0.49\n",
      "samples/36.txt 0.05\n",
      "samples/37.txt 0.51\n",
      "samples/38.txt 0.88\n",
      "samples/39.txt 0.62\n",
      "samples/40.txt 0.9\n",
      "samples/41.txt 0.41\n",
      "samples/42.txt 0.6\n",
      "samples/43.txt 0.74\n",
      "samples/44.txt 0.6\n",
      "samples/45.txt 0.69\n",
      "samples/46.txt 0.82\n",
      "samples/47.txt 0.56\n",
      "samples/48.txt 0.35\n",
      "samples/49.txt 0.58\n",
      "samples/50.txt 0.14\n",
      "samples/51.txt 0.35\n",
      "samples/52.txt 0.55\n",
      "samples/53.txt 0.27\n",
      "samples/54.txt 0.71\n",
      "samples/55.txt 0.19\n",
      "samples/56.txt 0.74\n",
      "samples/57.txt 0.27\n",
      "samples/58.txt 0.88\n",
      "samples/59.txt 0.23\n",
      "samples/60.txt 0.19\n",
      "samples/61.txt 0.46\n",
      "samples/62.txt 0.52\n",
      "samples/63.txt 0.15\n",
      "samples/64.txt 0.21\n",
      "samples/65.txt 0.11\n",
      "samples/66.txt 0.25\n",
      "samples/67.txt 0.77\n",
      "samples/68.txt 0.52\n",
      "samples/69.txt 0.87\n",
      "samples/70.txt 0.94\n",
      "samples/71.txt 0.83\n",
      "samples/72.txt 0.11\n",
      "samples/73.txt 0.6\n",
      "samples/74.txt 0.92\n",
      "samples/75.txt 0.18\n",
      "samples/76.txt 0.09\n",
      "samples/77.txt 0.75\n",
      "samples/78.txt 0.97\n",
      "samples/79.txt 0.72\n",
      "samples/80.txt 0.94\n",
      "samples/81.txt 0.1\n",
      "samples/82.txt 0.58\n",
      "samples/83.txt 0.11\n",
      "samples/84.txt 0.26\n",
      "samples/85.txt 0.07\n",
      "samples/86.txt 0.58\n",
      "samples/87.txt 0.14\n",
      "samples/88.txt 0.99\n",
      "samples/89.txt 0.31\n",
      "samples/90.txt 0.06\n",
      "samples/91.txt 0.49\n",
      "samples/92.txt 0.81\n",
      "samples/93.txt 0.22\n",
      "samples/94.txt 0.3\n",
      "samples/95.txt 0.05\n",
      "samples/96.txt 0.77\n",
      "samples/97.txt 0.24\n",
      "samples/98.txt 0.85\n",
      "samples/99.txt 0.51\n",
      "samples/100.txt 0.97\n",
      "samples/101.txt 0.1\n",
      "samples/102.txt 0.19\n",
      "samples/103.txt 0.72\n",
      "samples/104.txt 0.47\n",
      "samples/105.txt 0.38\n",
      "samples/106.txt 0.89\n",
      "samples/107.txt 0.13\n",
      "samples/108.txt 0.53\n",
      "samples/109.txt 0.78\n",
      "samples/110.txt 0.39\n",
      "samples/111.txt 0.79\n",
      "samples/112.txt 0.95\n",
      "samples/113.txt 0.19\n",
      "samples/114.txt 0.85\n",
      "samples/115.txt 0.33\n",
      "samples/116.txt 0.59\n",
      "samples/117.txt 0.09\n",
      "samples/118.txt 0.58\n",
      "samples/119.txt 0.77\n",
      "samples/120.txt 0.42\n",
      "samples/121.txt 0.84\n",
      "samples/122.txt 0.65\n",
      "samples/123.txt 0.3\n",
      "samples/124.txt 0.67\n",
      "samples/125.txt 0.64\n",
      "samples/126.txt 0.62\n",
      "samples/127.txt 0.43\n",
      "samples/128.txt 0.82\n",
      "samples/129.txt 0.42\n",
      "samples/130.txt 0.43\n",
      "samples/131.txt 0.15\n",
      "samples/132.txt 0.49\n",
      "samples/133.txt 0.91\n",
      "samples/134.txt 0.75\n",
      "samples/135.txt 0.36\n",
      "samples/136.txt 0.36\n",
      "samples/137.txt 0.87\n",
      "samples/138.txt 0.68\n",
      "samples/139.txt 0.67\n",
      "samples/140.txt 0.41\n",
      "samples/141.txt 0.14\n",
      "samples/142.txt 0.28\n",
      "samples/143.txt 0.5\n",
      "samples/144.txt 0.14\n",
      "samples/145.txt 0.29\n",
      "samples/146.txt 0.02\n",
      "samples/147.txt 0.21\n",
      "samples/148.txt 0.53\n",
      "samples/149.txt 0.58\n",
      "samples/150.txt 0.77\n",
      "samples/151.txt 0.79\n",
      "samples/152.txt 0.22\n",
      "samples/153.txt 0.58\n",
      "samples/154.txt 0.19\n",
      "samples/155.txt 0.83\n",
      "samples/156.txt 0.77\n",
      "samples/157.txt 0.25\n",
      "samples/158.txt 0.96\n",
      "samples/159.txt 0.21\n",
      "samples/160.txt 0.72\n",
      "samples/161.txt 0.07\n",
      "samples/162.txt 0.41\n",
      "samples/163.txt 0.96\n",
      "samples/164.txt 0.01\n",
      "samples/165.txt 0.53\n",
      "samples/166.txt 0.19\n",
      "samples/167.txt 0.04\n",
      "samples/168.txt 0.14\n",
      "samples/169.txt 0.51\n",
      "samples/170.txt 0.67\n",
      "samples/171.txt 0.33\n",
      "samples/172.txt 0.43\n",
      "samples/173.txt 0.53\n",
      "samples/174.txt 0.48\n",
      "samples/175.txt 0.17\n",
      "samples/176.txt 0.62\n",
      "samples/177.txt 0.14\n",
      "samples/178.txt 0.8\n",
      "samples/179.txt 0.64\n",
      "samples/180.txt 0.22\n",
      "samples/181.txt 0.22\n",
      "samples/182.txt 0.1\n",
      "samples/183.txt 0.73\n",
      "samples/184.txt 0.38\n",
      "samples/185.txt 0.15\n",
      "samples/186.txt 0.54\n",
      "samples/187.txt 0.72\n",
      "samples/188.txt 0.68\n",
      "samples/189.txt 0.91\n",
      "samples/190.txt 0.75\n",
      "samples/191.txt 0.15\n",
      "samples/192.txt 0.13\n",
      "samples/193.txt 0.07\n",
      "samples/194.txt 0.18\n",
      "samples/195.txt 0.77\n",
      "samples/196.txt 0.66\n",
      "samples/197.txt 0.53\n",
      "samples/198.txt 0.04\n",
      "samples/199.txt 0.31\n",
      "samples/200.txt 0.61\n",
      "samples/201.txt 0.5\n",
      "samples/202.txt 0.3\n",
      "samples/203.txt 0.84\n",
      "samples/204.txt 0.63\n",
      "samples/205.txt 0.77\n",
      "samples/206.txt 0.1\n",
      "samples/207.txt 1.0\n",
      "samples/208.txt 0.97\n",
      "samples/209.txt 0.79\n",
      "samples/210.txt 0.83\n",
      "samples/211.txt 0.67\n",
      "samples/212.txt 0.09\n",
      "samples/213.txt 0.25\n",
      "samples/214.txt 0.58\n",
      "samples/215.txt 0.85\n",
      "samples/216.txt 0.11\n",
      "samples/217.txt 0.31\n",
      "samples/218.txt 0.19\n",
      "samples/219.txt 0.71\n",
      "samples/220.txt 0.44\n",
      "samples/221.txt 1.0\n",
      "samples/222.txt 0.85\n",
      "samples/223.txt 0.56\n",
      "samples/224.txt 0.79\n",
      "samples/225.txt 0.66\n",
      "samples/226.txt 0.34\n",
      "samples/227.txt 0.58\n",
      "samples/228.txt 0.91\n",
      "samples/229.txt 0.29\n",
      "samples/230.txt 0.12\n",
      "samples/231.txt 0.47\n",
      "samples/232.txt 0.11\n",
      "samples/233.txt 1.0\n",
      "samples/234.txt 0.04\n",
      "samples/235.txt 0.89\n",
      "samples/236.txt 0.56\n",
      "samples/237.txt 0.31\n",
      "samples/238.txt 0.4\n",
      "samples/239.txt 0.96\n",
      "samples/240.txt 0.86\n",
      "samples/241.txt 0.36\n",
      "samples/242.txt 0.84\n",
      "samples/243.txt 0.5\n",
      "samples/244.txt 0.45\n",
      "samples/245.txt 0.36\n",
      "samples/246.txt 0.74\n",
      "samples/247.txt 0.03\n",
      "samples/248.txt 0.67\n",
      "samples/249.txt 0.97\n",
      "samples/250.txt 0.22\n",
      "samples/251.txt 0.36\n",
      "samples/252.txt 0.15\n",
      "samples/253.txt 0.72\n",
      "samples/254.txt 0.28\n",
      "samples/255.txt 0.51\n",
      "samples/256.txt 0.25\n",
      "samples/257.txt 0.81\n",
      "samples/258.txt 0.88\n",
      "samples/259.txt 0.04\n",
      "samples/260.txt 0.16\n",
      "samples/261.txt 0.71\n",
      "samples/262.txt 0.5\n",
      "samples/263.txt 0.86\n",
      "samples/264.txt 0.33\n",
      "samples/265.txt 0.53\n",
      "samples/266.txt 0.42\n",
      "samples/267.txt 0.32\n",
      "samples/268.txt 0.01\n",
      "samples/269.txt 0.51\n",
      "samples/270.txt 0.79\n",
      "samples/271.txt 0.11\n",
      "samples/272.txt 0.45\n",
      "samples/273.txt 0.3\n",
      "samples/274.txt 0.39\n",
      "samples/275.txt 0.96\n",
      "samples/276.txt 0.45\n",
      "samples/277.txt 0.01\n",
      "samples/278.txt 0.62\n",
      "samples/279.txt 0.06\n",
      "samples/280.txt 0.62\n",
      "samples/281.txt 0.45\n",
      "samples/282.txt 0.21\n",
      "samples/283.txt 0.31\n",
      "samples/284.txt 0.44\n",
      "samples/285.txt 0.17\n",
      "samples/286.txt 0.71\n",
      "samples/287.txt 0.28\n",
      "samples/288.txt 0.87\n",
      "samples/289.txt 0.65\n",
      "samples/290.txt 0.33\n",
      "samples/291.txt 0.4\n",
      "samples/292.txt 0.61\n",
      "samples/293.txt 0.34\n",
      "samples/294.txt 0.01\n",
      "samples/295.txt 0.25\n",
      "samples/296.txt 0.35\n",
      "samples/297.txt 0.74\n",
      "samples/298.txt 0.67\n",
      "samples/299.txt 0.29\n",
      "samples/300.txt 0.93\n",
      "samples/301.txt 0.67\n",
      "samples/302.txt 0.76\n",
      "samples/303.txt 0.81\n",
      "samples/304.txt 0.98\n",
      "samples/305.txt 0.79\n",
      "samples/306.txt 0.37\n",
      "samples/307.txt 0.78\n",
      "samples/308.txt 0.72\n",
      "samples/309.txt 0.41\n",
      "samples/310.txt 0.39\n",
      "samples/311.txt 0.51\n",
      "samples/312.txt 0.64\n",
      "samples/313.txt 0.48\n",
      "samples/314.txt 0.46\n",
      "samples/315.txt 0.71\n",
      "samples/316.txt 0.21\n",
      "samples/317.txt 0.05\n",
      "samples/318.txt 0.55\n",
      "samples/319.txt 0.33\n",
      "samples/320.txt 0.99\n",
      "samples/321.txt 1.0\n",
      "samples/322.txt 0.95\n",
      "samples/323.txt 0.47\n",
      "samples/324.txt 0.06\n",
      "samples/325.txt 0.94\n",
      "samples/326.txt 0.36\n",
      "samples/327.txt 0.49\n",
      "samples/328.txt 0.61\n",
      "samples/329.txt 0.61\n",
      "samples/330.txt 0.75\n",
      "samples/331.txt 0.68\n",
      "samples/332.txt 0.87\n",
      "samples/333.txt 0.96\n",
      "samples/334.txt 0.65\n",
      "samples/335.txt 0.42\n",
      "samples/336.txt 0.46\n",
      "samples/337.txt 0.72\n",
      "samples/338.txt 0.62\n",
      "samples/339.txt 0.14\n",
      "samples/340.txt 0.39\n",
      "samples/341.txt 0.83\n",
      "samples/342.txt 0.87\n",
      "samples/343.txt 0.31\n",
      "samples/344.txt 0.3\n",
      "samples/345.txt 0.45\n",
      "samples/346.txt 0.77\n",
      "samples/347.txt 0.55\n",
      "samples/348.txt 0.94\n",
      "samples/349.txt 0.18\n",
      "samples/350.txt 0.15\n",
      "samples/351.txt 0.06\n",
      "samples/352.txt 0.17\n",
      "samples/353.txt 0.18\n",
      "samples/354.txt 0.06\n",
      "samples/355.txt 0.78\n",
      "samples/356.txt 0.18\n",
      "samples/357.txt 0.41\n",
      "samples/358.txt 0.05\n",
      "samples/359.txt 0.17\n",
      "samples/360.txt 0.5\n",
      "samples/361.txt 0.42\n",
      "samples/362.txt 0.38\n",
      "samples/363.txt 0.82\n",
      "samples/364.txt 0.05\n",
      "samples/365.txt 0.81\n",
      "samples/366.txt 0.51\n",
      "samples/367.txt 0.08\n",
      "samples/368.txt 0.8\n",
      "samples/369.txt 0.14\n",
      "samples/370.txt 0.56\n",
      "samples/371.txt 0.92\n",
      "samples/372.txt 0.01\n",
      "samples/373.txt 0.48\n",
      "samples/374.txt 0.61\n",
      "samples/375.txt 0.44\n",
      "samples/376.txt 0.21\n",
      "samples/377.txt 0.36\n",
      "samples/378.txt 0.29\n",
      "samples/379.txt 0.07\n",
      "samples/380.txt 0.35\n",
      "samples/381.txt 0.85\n",
      "samples/382.txt 0.42\n",
      "samples/383.txt 0.72\n",
      "samples/384.txt 0.63\n",
      "samples/385.txt 0.07\n",
      "samples/386.txt 0.49\n",
      "samples/387.txt 0.52\n",
      "samples/388.txt 0.43\n",
      "samples/389.txt 0.59\n",
      "samples/390.txt 0.27\n",
      "samples/391.txt 0.14\n",
      "samples/392.txt 0.84\n",
      "samples/393.txt 0.88\n",
      "samples/394.txt 0.54\n",
      "samples/395.txt 0.9\n",
      "samples/396.txt 0.19\n",
      "samples/397.txt 0.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples/398.txt 0.31\n",
      "samples/399.txt 0.76\n",
      "samples/400.txt 0.91\n",
      "samples/401.txt 0.44\n",
      "samples/402.txt 0.04\n",
      "samples/403.txt 0.02\n",
      "samples/404.txt 0.58\n",
      "samples/405.txt 0.39\n",
      "samples/406.txt 0.45\n",
      "samples/407.txt 0.14\n",
      "samples/408.txt 0.92\n",
      "samples/409.txt 0.41\n",
      "samples/410.txt 0.92\n",
      "samples/411.txt 0.33\n",
      "samples/412.txt 0.74\n",
      "samples/413.txt 0.67\n",
      "samples/414.txt 0.29\n",
      "samples/415.txt 0.12\n",
      "samples/416.txt 0.15\n",
      "samples/417.txt 0.56\n",
      "samples/418.txt 0.24\n",
      "samples/419.txt 0.77\n",
      "samples/420.txt 0.97\n",
      "samples/421.txt 0.38\n",
      "samples/422.txt 0.42\n",
      "samples/423.txt 0.94\n",
      "samples/424.txt 0.56\n",
      "samples/425.txt 0.91\n",
      "samples/426.txt 0.95\n",
      "samples/427.txt 0.63\n",
      "samples/428.txt 0.35\n",
      "samples/429.txt 0.49\n",
      "samples/430.txt 0.89\n",
      "samples/431.txt 0.9\n",
      "samples/432.txt 0.63\n",
      "samples/433.txt 0.11\n",
      "samples/434.txt 0.55\n",
      "samples/435.txt 0.95\n",
      "samples/436.txt 0.46\n",
      "samples/437.txt 0.97\n",
      "samples/438.txt 0.97\n",
      "samples/439.txt 0.24\n",
      "samples/440.txt 0.36\n",
      "samples/441.txt 0.41\n",
      "samples/442.txt 0.54\n",
      "samples/443.txt 0.73\n",
      "samples/444.txt 0.36\n",
      "samples/445.txt 0.15\n",
      "samples/446.txt 0.94\n",
      "samples/447.txt 0.12\n",
      "samples/448.txt 0.02\n",
      "samples/449.txt 0.72\n",
      "samples/450.txt 0.72\n",
      "samples/451.txt 0.88\n",
      "samples/452.txt 0.19\n",
      "samples/453.txt 0.07\n",
      "samples/454.txt 0.22\n",
      "samples/455.txt 0.83\n",
      "samples/456.txt 0.81\n",
      "samples/457.txt 0.4\n",
      "samples/458.txt 0.45\n",
      "samples/459.txt 0.31\n",
      "samples/460.txt 0.8\n",
      "samples/461.txt 0.44\n",
      "samples/462.txt 0.29\n",
      "samples/463.txt 0.66\n",
      "samples/464.txt 0.87\n",
      "samples/465.txt 0.95\n",
      "samples/466.txt 0.73\n",
      "samples/467.txt 0.88\n",
      "samples/468.txt 0.56\n",
      "samples/469.txt 0.66\n",
      "samples/470.txt 0.13\n",
      "samples/471.txt 0.56\n",
      "samples/472.txt 0.49\n",
      "samples/473.txt 0.97\n",
      "samples/474.txt 0.16\n",
      "samples/475.txt 0.65\n",
      "samples/476.txt 0.46\n",
      "samples/477.txt 0.8\n",
      "samples/478.txt 0.99\n",
      "samples/479.txt 0.85\n",
      "samples/480.txt 0.56\n",
      "samples/481.txt 0.36\n",
      "samples/482.txt 0.95\n",
      "samples/483.txt 0.86\n",
      "samples/484.txt 0.66\n",
      "samples/485.txt 0.64\n",
      "samples/486.txt 0.54\n",
      "samples/487.txt 0.33\n",
      "samples/488.txt 0.89\n",
      "samples/489.txt 0.95\n",
      "samples/490.txt 0.24\n",
      "samples/491.txt 0.75\n",
      "samples/492.txt 0.33\n",
      "samples/493.txt 0.33\n",
      "samples/494.txt 0.59\n",
      "samples/495.txt 0.1\n",
      "samples/496.txt 0.32\n",
      "samples/497.txt 0.44\n",
      "samples/498.txt 0.1\n",
      "samples/499.txt 0.26\n",
      "samples/500.txt 0.93\n",
      "samples/501.txt 0.47\n",
      "samples/502.txt 0.26\n",
      "samples/503.txt 0.71\n",
      "samples/504.txt 0.59\n",
      "samples/505.txt 0.85\n",
      "samples/506.txt 0.69\n",
      "samples/507.txt 0.59\n",
      "samples/508.txt 0.9\n",
      "samples/509.txt 0.09\n",
      "samples/510.txt 0.15\n",
      "samples/511.txt 0.55\n",
      "samples/512.txt 0.01\n",
      "samples/513.txt 0.87\n",
      "samples/514.txt 0.51\n",
      "samples/515.txt 0.65\n",
      "samples/516.txt 0.13\n",
      "samples/517.txt 0.17\n",
      "samples/518.txt 0.17\n",
      "samples/519.txt 0.31\n",
      "samples/520.txt 0.72\n",
      "samples/521.txt 0.26\n",
      "samples/522.txt 0.57\n",
      "samples/523.txt 0.71\n",
      "samples/524.txt 0.13\n",
      "samples/525.txt 0.63\n",
      "samples/526.txt 0.51\n",
      "samples/527.txt 0.41\n",
      "samples/528.txt 0.77\n",
      "samples/529.txt 0.45\n",
      "samples/530.txt 0.5\n",
      "samples/531.txt 0.15\n",
      "samples/532.txt 0.44\n",
      "samples/533.txt 0.96\n",
      "samples/534.txt 0.88\n",
      "samples/535.txt 0.78\n",
      "samples/536.txt 0.06\n",
      "samples/537.txt 0.86\n",
      "samples/538.txt 0.95\n",
      "samples/539.txt 0.61\n",
      "samples/540.txt 0.04\n",
      "samples/541.txt 0.62\n",
      "samples/542.txt 0.09\n",
      "samples/543.txt 0.07\n",
      "samples/544.txt 0.67\n",
      "samples/545.txt 0.8\n",
      "samples/546.txt 0.45\n",
      "samples/547.txt 0.81\n",
      "samples/548.txt 0.82\n",
      "samples/549.txt 0.98\n",
      "samples/550.txt 0.9\n",
      "samples/551.txt 0.97\n",
      "samples/552.txt 0.66\n",
      "samples/553.txt 0.34\n",
      "samples/554.txt 0.09\n",
      "samples/555.txt 0.96\n",
      "samples/556.txt 0.98\n",
      "samples/557.txt 0.01\n",
      "samples/558.txt 0.03\n",
      "samples/559.txt 0.29\n",
      "samples/560.txt 0.98\n",
      "samples/561.txt 0.72\n",
      "samples/562.txt 0.63\n",
      "samples/563.txt 0.03\n",
      "samples/564.txt 0.39\n",
      "samples/565.txt 0.36\n",
      "samples/566.txt 0.17\n",
      "samples/567.txt 0.96\n",
      "samples/568.txt 0.51\n",
      "samples/569.txt 1.0\n",
      "samples/570.txt 0.59\n",
      "samples/571.txt 0.91\n",
      "samples/572.txt 0.56\n",
      "samples/573.txt 0.51\n",
      "samples/574.txt 0.13\n",
      "samples/575.txt 0.08\n",
      "samples/576.txt 0.33\n",
      "samples/577.txt 0.31\n",
      "samples/578.txt 0.37\n",
      "samples/579.txt 0.45\n",
      "samples/580.txt 0.95\n",
      "samples/581.txt 0.16\n",
      "samples/582.txt 0.65\n",
      "samples/583.txt 0.38\n",
      "samples/584.txt 0.89\n",
      "samples/585.txt 0.07\n",
      "samples/586.txt 0.99\n",
      "samples/587.txt 0.7\n",
      "samples/588.txt 1.0\n",
      "samples/589.txt 0.01\n",
      "samples/590.txt 0.71\n",
      "samples/591.txt 0.37\n",
      "samples/592.txt 0.92\n",
      "samples/593.txt 0.02\n",
      "samples/594.txt 0.95\n",
      "samples/595.txt 0.54\n",
      "samples/596.txt 0.14\n",
      "samples/597.txt 0.67\n",
      "samples/598.txt 0.6\n",
      "samples/599.txt 0.77\n",
      "samples/600.txt 0.34\n",
      "samples/601.txt 0.84\n",
      "samples/602.txt 0.74\n",
      "samples/603.txt 0.58\n",
      "samples/604.txt 0.17\n",
      "samples/605.txt 0.42\n",
      "samples/606.txt 0.87\n",
      "samples/607.txt 0.57\n",
      "samples/608.txt 0.77\n",
      "samples/609.txt 0.08\n",
      "samples/610.txt 0.91\n",
      "samples/611.txt 0.09\n",
      "samples/612.txt 0.17\n",
      "samples/613.txt 0.7\n",
      "samples/614.txt 0.75\n",
      "samples/615.txt 0.09\n",
      "samples/616.txt 0.34\n",
      "samples/617.txt 0.76\n",
      "samples/618.txt 0.64\n",
      "samples/619.txt 0.98\n",
      "samples/620.txt 0.9\n",
      "samples/621.txt 0.97\n",
      "samples/622.txt 0.64\n",
      "samples/623.txt 0.07\n",
      "samples/624.txt 0.67\n",
      "samples/625.txt 0.76\n",
      "samples/626.txt 0.88\n",
      "samples/627.txt 0.67\n",
      "samples/628.txt 0.15\n",
      "samples/629.txt 0.33\n",
      "samples/630.txt 0.28\n",
      "samples/631.txt 0.7\n",
      "samples/632.txt 0.4\n",
      "samples/633.txt 0.96\n",
      "samples/634.txt 0.98\n",
      "samples/635.txt 0.88\n",
      "samples/636.txt 0.87\n",
      "samples/637.txt 0.73\n",
      "samples/638.txt 0.67\n",
      "samples/639.txt 0.89\n",
      "samples/640.txt 0.55\n",
      "samples/641.txt 0.97\n",
      "samples/642.txt 0.56\n",
      "samples/643.txt 0.7\n",
      "samples/644.txt 0.03\n",
      "samples/645.txt 0.14\n",
      "samples/646.txt 0.13\n",
      "samples/647.txt 0.36\n",
      "samples/648.txt 0.81\n",
      "samples/649.txt 0.95\n",
      "samples/650.txt 0.17\n",
      "samples/651.txt 0.86\n",
      "samples/652.txt 0.11\n",
      "samples/653.txt 0.81\n",
      "samples/654.txt 0.16\n",
      "samples/655.txt 0.65\n",
      "samples/656.txt 0.66\n",
      "samples/657.txt 0.04\n",
      "samples/658.txt 0.5\n",
      "samples/659.txt 0.38\n",
      "samples/660.txt 0.46\n",
      "samples/661.txt 0.24\n",
      "samples/662.txt 0.4\n",
      "samples/663.txt 0.38\n",
      "samples/664.txt 0.92\n",
      "samples/665.txt 0.31\n",
      "samples/666.txt 0.81\n",
      "samples/667.txt 0.03\n",
      "samples/668.txt 0.01\n",
      "samples/669.txt 0.75\n",
      "samples/670.txt 0.39\n",
      "samples/671.txt 0.28\n",
      "samples/672.txt 0.85\n",
      "samples/673.txt 0.64\n",
      "samples/674.txt 0.46\n",
      "samples/675.txt 0.39\n",
      "samples/676.txt 0.57\n",
      "samples/677.txt 0.45\n",
      "samples/678.txt 1.0\n",
      "samples/679.txt 0.44\n",
      "samples/680.txt 0.76\n",
      "samples/681.txt 0.15\n",
      "samples/682.txt 0.86\n",
      "samples/683.txt 0.39\n",
      "samples/684.txt 0.22\n",
      "samples/685.txt 0.67\n",
      "samples/686.txt 0.04\n",
      "samples/687.txt 0.31\n",
      "samples/688.txt 0.14\n",
      "samples/689.txt 0.62\n",
      "samples/690.txt 0.56\n",
      "samples/691.txt 0.49\n",
      "samples/692.txt 0.51\n",
      "samples/693.txt 0.48\n",
      "samples/694.txt 0.34\n",
      "samples/695.txt 0.92\n",
      "samples/696.txt 0.92\n",
      "samples/697.txt 0.09\n",
      "samples/698.txt 0.56\n",
      "samples/699.txt 0.12\n",
      "samples/700.txt 0.8\n",
      "samples/701.txt 0.79\n",
      "samples/702.txt 0.01\n",
      "samples/703.txt 0.55\n",
      "samples/704.txt 0.72\n",
      "samples/705.txt 0.35\n",
      "samples/706.txt 0.39\n",
      "samples/707.txt 0.87\n",
      "samples/708.txt 0.44\n",
      "samples/709.txt 0.13\n",
      "samples/710.txt 0.23\n",
      "samples/711.txt 0.34\n",
      "samples/712.txt 0.65\n",
      "samples/713.txt 0.52\n",
      "samples/714.txt 0.31\n",
      "samples/715.txt 0.41\n",
      "samples/716.txt 0.38\n",
      "samples/717.txt 0.29\n",
      "samples/718.txt 1.0\n",
      "samples/719.txt 0.84\n",
      "samples/720.txt 0.89\n",
      "samples/721.txt 0.03\n",
      "samples/722.txt 0.25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-34-a634dc93ab21>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0mfile\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"This sample's Temperature: \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcur_temp\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"\\n\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m     \u001B[0mfile\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgenerate_text\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcur_temp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstart_string\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseed_word\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m     \u001B[0mfile\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-32-dd715ca4782e>\u001B[0m in \u001B[0;36mgenerate_text\u001B[0;34m(model, temperature, start_string)\u001B[0m\n\u001B[1;32m     19\u001B[0m   \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreset_states\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m   \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_generate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m     \u001B[0mpredictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_eval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m     \u001B[0;31m# remove the batch dimension\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m     \u001B[0mpredictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    983\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    984\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menable_auto_cast_variables\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 985\u001B[0;31m           \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    986\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    987\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    370\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilt\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    371\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_init_graph_network\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 372\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSequential\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtraining\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    373\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    374\u001B[0m     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minputs\u001B[0m  \u001B[0;31m# handle the corner case where self.layers is empty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    383\u001B[0m         \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0mtensors\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mthere\u001B[0m \u001B[0mare\u001B[0m \u001B[0mmore\u001B[0m \u001B[0mthan\u001B[0m \u001B[0mone\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    384\u001B[0m     \"\"\"\n\u001B[0;32m--> 385\u001B[0;31m     return self._run_internal_graph(\n\u001B[0m\u001B[1;32m    386\u001B[0m         inputs, training=training, mask=mask)\n\u001B[1;32m    387\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001B[0m in \u001B[0;36m_run_internal_graph\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    506\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    507\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnode\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_arguments\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 508\u001B[0;31m         \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnode\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    509\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    510\u001B[0m         \u001B[0;31m# Update tensor_dict.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, inputs, initial_state, constants, **kwargs)\u001B[0m\n\u001B[1;32m    661\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    662\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0minitial_state\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mconstants\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 663\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mRNN\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    664\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    665\u001B[0m     \u001B[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    983\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    984\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menable_auto_cast_variables\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 985\u001B[0;31m           \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    986\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    987\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs, mask, training, initial_state)\u001B[0m\n\u001B[1;32m    438\u001B[0m       \u001B[0mruntime\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_runtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_RUNTIME_UNKNOWN\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    439\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 440\u001B[0;31m       last_output, outputs, runtime, states = self._defun_gru_call(\n\u001B[0m\u001B[1;32m    441\u001B[0m           inputs, initial_state, training, mask, row_lengths)\n\u001B[1;32m    442\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001B[0m in \u001B[0;36m_defun_gru_call\u001B[0;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001B[0m\n\u001B[1;32m    496\u001B[0m         \u001B[0mlast_output\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_h\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mruntime\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgpu_gru\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mgpu_gru_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    497\u001B[0m       \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 498\u001B[0;31m         \u001B[0mlast_output\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_h\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mruntime\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstandard_gru\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mnormal_gru_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    499\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    500\u001B[0m       last_output, outputs, new_h, runtime = gru_with_backend_selection(\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001B[0m in \u001B[0;36mstandard_gru\u001B[0;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001B[0m\n\u001B[1;32m    573\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mh\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mh\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    574\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 575\u001B[0;31m   last_output, outputs, new_states = K.rnn(\n\u001B[0m\u001B[1;32m    576\u001B[0m       \u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    577\u001B[0m       \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0minit_h\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    200\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 201\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    202\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001B[0m in \u001B[0;36mrnn\u001B[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001B[0m\n\u001B[1;32m   4356\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput_ta_t\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnew_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4357\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4358\u001B[0;31m       final_outputs = control_flow_ops.while_loop(\n\u001B[0m\u001B[1;32m   4359\u001B[0m           \u001B[0mbody\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0m_step\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4360\u001B[0m           \u001B[0mloop_vars\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput_ta\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstates\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001B[0m in \u001B[0;36mwhile_loop\u001B[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001B[0m\n\u001B[1;32m   2733\u001B[0m                                               list(loop_vars))\n\u001B[1;32m   2734\u001B[0m       \u001B[0;32mwhile\u001B[0m \u001B[0mcond\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2735\u001B[0;31m         \u001B[0mloop_vars\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbody\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2736\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtry_to_pack\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_basetuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2737\u001B[0m           \u001B[0mpacked\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001B[0m in \u001B[0;36m_step\u001B[0;34m(time, output_ta_t, *states)\u001B[0m\n\u001B[1;32m   4342\u001B[0m         \u001B[0mcurrent_input\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mta\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mta\u001B[0m \u001B[0;32min\u001B[0m \u001B[0minput_ta\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4343\u001B[0m         \u001B[0mcurrent_input\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpack_sequence_as\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcurrent_input\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4344\u001B[0;31m         output, new_states = step_function(current_input,\n\u001B[0m\u001B[1;32m   4345\u001B[0m                                            tuple(states) + tuple(constants))\n\u001B[1;32m   4346\u001B[0m         \u001B[0mflat_state\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(cell_inputs, cell_states)\u001B[0m\n\u001B[1;32m    560\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    561\u001B[0m     \u001B[0;31m# hidden state projected by all gate matrices at once\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 562\u001B[0;31m     \u001B[0mmatrix_inner\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mK\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mh_tm1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecurrent_kernel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    563\u001B[0m     \u001B[0mmatrix_inner\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mK\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias_add\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmatrix_inner\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecurrent_bias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    564\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    200\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 201\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    202\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001B[0m in \u001B[0;36mdot\u001B[0;34m(x, y)\u001B[0m\n\u001B[1;32m   1829\u001B[0m     \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msparse_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msparse_tensor_dense_matmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1830\u001B[0m   \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1831\u001B[0;31m     \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmath_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1832\u001B[0m   \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1833\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    200\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 201\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    202\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001B[0m in \u001B[0;36mmatmul\u001B[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001B[0m\n\u001B[1;32m   3252\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mret\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3253\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3254\u001B[0;31m       return gen_math_ops.mat_mul(\n\u001B[0m\u001B[1;32m   3255\u001B[0m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001B[1;32m   3256\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/hub/cs/code/python/poetryGen/ramke-env/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001B[0m in \u001B[0;36mmat_mul\u001B[0;34m(a, b, transpose_a, transpose_b, name)\u001B[0m\n\u001B[1;32m   5616\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mtld\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_eager\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5617\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5618\u001B[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001B[0m\u001B[1;32m   5619\u001B[0m         \u001B[0m_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_context_handle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtld\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"MatMul\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5620\u001B[0m         \u001B[0mtld\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mop_callbacks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"transpose_a\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtranspose_a\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"transpose_b\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# print(generate_text(model, start_string=u\" \"))\n",
    "for i in range(1,25001):    \n",
    "    random.seed()\n",
    "    \n",
    "    filename = \"samples/\" + str(i) + \".txt\"\n",
    "    cur_temp = random.randint(1,100)/100\n",
    "    \n",
    "    seed_word = word_list.readline().strip() + \" \"\n",
    "    \n",
    "    print(filename + \" \" + str(cur_temp))\n",
    "    file = open(filename, \"w\")\n",
    "    \n",
    "    file.write(\"This sample's Temperature: \" + str(cur_temp) + \"\\n\")\n",
    "    file.write(generate_text(model, cur_temp, start_string=str(seed_word)))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}